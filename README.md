<h1 align="center">Hi ðŸ‘‹, I'm MD Zeeshan</h1>
<h3 align="center">Big Data Engineer | PySpark | AWS EMR | Hive | Data Pipelines</h3>

<p align="center">
  <img src="https://img.shields.io/badge/Big%20Data-Spark-orange?style=for-the-badge" />
  <img src="https://img.shields.io/badge/PySpark-Data%20Processing-blue?style=for-the-badge" />
  <img src="https://img.shields.io/badge/AWS-EMR-yellow?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Hive-Data%20Warehouse-green?style=for-the-badge" />
</p>

---

## ðŸŒŸ About Me (Minimal + Professional)
- Passionate about **Big Data engineering**, distributed systems, and cloud data processing.  
- Skilled in **Spark, PySpark, Hive, AWS EMR, SQL, Python**.  
- I enjoy building data pipelines, improving performance, and designing efficient data flows.  
- Interested in scalable architectures and automation.

---

## ðŸ§  Skills Overview (Clean + Modern)
### **Big Data / Cloud**
`Apache Spark` Â· `PySpark` Â· `Hadoop` Â· `Hive` Â· `AWS EMR` Â· `Amazon S3`

### **Programming**
`Python` Â· `SQL` Â· `Java`

### **Databases**
`MySQL` Â· `Hive`

### **Data Engineering Concepts**
`ETL Pipelines` Â· `Distributed Computing` Â· `Data Modeling` Â· `Schema Design`

---

## ðŸ”§ Tech Stack Badges (Fancy Style)

**Languages:**  
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-025E8C?style=flat)
![Java](https://img.shields.io/badge/Java-orange?style=flat)

**Big Data:**  
![Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=flat&logo=apache-spark&logoColor=white)
![Hadoop](https://img.shields.io/badge/Hadoop-FFCC00?style=flat)
![Hive](https://img.shields.io/badge/Hive-FFC300?style=flat)

**Cloud:**  
![AWS](https://img.shields.io/badge/AWS-232F3E?style=flat&logo=amazon-aws&logoColor=white)

---

## ðŸ“‚ Projects (Ultra Simple + Big-Data Focused)

### ðŸ”¹ **Hadoop Semi-Structured Data Processing with Avro**
- ETL pipeline using **Sqoop** into Hive.  
- Semi-structured data stored in **Avro** with schema evolution.  
- Automated incremental loading & optimized Hive queries.

### ðŸ”¹ **Sparkâ€“Hive JSON Data Processing Pipeline**
- Ingested JSON from APIs & HDFS using **PySpark DataFrames**.  
- Performed cleansing, joins, aggregations, transformations.  
- Loaded final results into **Hive** for analytics.

---

## ðŸŒ“ Dark Mode GitHub Stats (Dark + Fancy)

<p align="center">
<img src="https://github-readme-stats.vercel.app/api?username=cd-mdzeeshan&show_icons=true&theme=tokyonight" />
</p>

<p align="center">
<img src="https://github-readme-stats.vercel.app/api/top-langs/?username=cd-mdzeeshan&layout=compact&theme=tokyonight" />
</p>

---

## ðŸ”— Connect With Me
- **LinkedIn:** https://linkedin.com/in/md-zeeshan-b5a35a17a  
- **Email:** md.zeeshan.bigdata@gmail.com  

---

## âœ” Summary of This README
This single README includes:

- **Minimal professional sections**  
- **Fancy badges and modern styles**  
- **Big-data-specific branding**  
- **Dark mode stats**  
- **Ultra simple project descriptions**  

A perfect all-in-one profile for recruiters, developers, and the GitHub community.

