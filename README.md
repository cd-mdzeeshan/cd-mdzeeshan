<h1 align="center">Hi , I'm MD Zeeshan</h1>
<h3 align="center">Big Data Engineer | PySpark | AWS EMR | Hive | Data Pipelines</h3>

<p align="center">
  <img src="https://img.shields.io/badge/Big%20Data-Spark-orange?style=for-the-badge" />
  <img src="https://img.shields.io/badge/PySpark-Data%20Processing-blue?style=for-the-badge" />
  <img src="https://img.shields.io/badge/AWS-EMR-yellow?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Hive-Data%20Warehouse-green?style=for-the-badge" />
</p>

---

##  About Me (Minimal + Professional)
- Passionate about **Big Data engineering**, distributed systems, and cloud data processing.  
- Skilled in **Spark, PySpark, Hive, AWS EMR, SQL, Python**.  
- I enjoy building data pipelines, improving performance, and designing efficient data flows.  
- Interested in scalable architectures and automation.

---

##  Skills Overview (Clean + Modern)
### **Big Data / Cloud**
`Apache Spark` 路 `PySpark` 路 `Hadoop` 路 `Hive` 路 `AWS EMR` 路 `Amazon S3`

### **Programming**
`Python` 路 `SQL` 路 `Java`

### **Databases**
`MySQL` 路 `Hive`

### **Data Engineering Concepts**
`ETL Pipelines` 路 `Distributed Computing` 路 `Data Modeling` 路 `Schema Design`

---

##  Tech Stack Badges (Fancy Style)

**Languages:**  
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-025E8C?style=flat)
![Java](https://img.shields.io/badge/Java-orange?style=flat)

**Big Data:**  
![Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=flat&logo=apache-spark&logoColor=white)
![Hadoop](https://img.shields.io/badge/Hadoop-FFCC00?style=flat)
![Hive](https://img.shields.io/badge/Hive-FFC300?style=flat)

**Cloud:**  
![AWS](https://img.shields.io/badge/AWS-232F3E?style=flat&logo=amazon-aws&logoColor=white)

---

##  Projects (Ultra Simple + Big-Data Focused)

###  **Hadoop Semi-Structured Data Processing with Avro**
- ETL pipeline using **Sqoop** into Hive.  
- Semi-structured data stored in **Avro** with schema evolution.  
- Automated incremental loading & optimized Hive queries.

###  **SparkHive JSON Data Processing Pipeline**
- Ingested JSON from APIs & HDFS using **PySpark DataFrames**.  
- Performed cleansing, joins, aggregations, transformations.  
- Loaded final results into **Hive** for analytics.

---

##  Dark Mode GitHub Stats (Dark + Fancy)

<p align="center">
  <img src="https://github-readme-activity-graph.vercel.app/graph?username=cd-mdzeeshan&theme=tokyo-night" />
</p>

<p align="center">
  <img src="https://github-readme-stats-salesp07.vercel.app/api?username=cd-mdzeeshan&show_icons=true&theme=tokyonight" />
</p>



---

##  Connect With Me
- **LinkedIn:** https://linkedin.com/in/md-zeeshan-b5a35a17a  
- **Email:** md.zeeshan.bigdata@gmail.com  



